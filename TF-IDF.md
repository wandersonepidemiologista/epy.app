# O que Ã© TF-IDF?  

O **TF-IDF (Term Frequency - Inverse Document Frequency)** Ã© uma tÃ©cnica utilizada para avaliar a importÃ¢ncia de uma palavra dentro de um conjunto de textos (corpus). Ele combina dois fatores:  

## 1. TF (Term Frequency) â€“ FrequÃªncia do termo no documento  
Mede quantas vezes um termo aparece dentro de um documento em relaÃ§Ã£o ao total de palavras no documento.  

A fÃ³rmula Ã©:  

$$
TF(t) = \frac{\text{NÃºmero de vezes que a palavra } t \text{ aparece no documento}}{\text{Total de palavras no documento}}
$$

**Exemplo:**  
Se a palavra *"trem"* aparece 3 vezes em um texto de 100 palavras, entÃ£o:  

$$
TF(\text{"trem"}) = \frac{3}{100} = 0.03
$$  

## 2. IDF (Inverse Document Frequency) â€“ FrequÃªncia inversa do documento  
Mede o quÃ£o rara ou comum uma palavra Ã© dentro de um conjunto de documentos.  

A fÃ³rmula Ã©:  

$$
IDF(t) = \log \left( \frac{N}{n_t} \right)
$$  

Onde:  
- \( N \) = Total de documentos no corpus  
- \( n_t \) = NÃºmero de documentos que contÃªm a palavra \( t \)  

**Exemplo:**  
Se a palavra *"trem"* aparece em apenas 1 de 10 documentos:  

$$
IDF(\text{"trem"}) = \log \left( \frac{10}{1} \right) = \log(10) = 1
$$  

## 3. CÃ¡lculo do TF-IDF  
O TF-IDF Ã© simplesmente o produto de TF e IDF:  

$$
TF-IDF(t) = TF(t) \times IDF(t)
$$  

**Exemplo:**  
Considerando os valores anteriores:  

$$
TF-IDF(\text{"trem"}) = 0.03 \times 1 = 0.03
$$  

Ou seja, quanto maior o valor de TF-IDF, mais relevante a palavra Ã© dentro do documento em comparaÃ§Ã£o ao restante do corpus.  

---

Esse conceito Ã© muito utilizado em **Machine Learning**, **Processamento de Linguagem Natural (NLP)** e sistemas de **busca** para determinar palavras importantes dentro de textos. ðŸš€
